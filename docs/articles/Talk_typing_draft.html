<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Typing and Talking: draft in progress • TalkTyping</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Typing and Talking: draft in progress">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">TalkTyping</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.9.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Paper and Scripts
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/E1A_Analysis.html">Analysis E1A Inner Speech Talk and Type</a>
    </li>
    <li>
      <a href="../articles/E1B_Analysis.html">Analysis E1B Talk and Type</a>
    </li>
    <li>
      <a href="../articles/E2_Analysis.html">Analysis E2 Verbal Suppression</a>
    </li>
    <li>
      <a href="../articles/Talk_typing_draft.html">Typing and Talking: draft in progress</a>
    </li>
  </ul>
</li>
<li>
  <a href="../articles/Talk_typing_draft.pdf">
    <span class="fa fa-file"></span>
     
    pdf
  </a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="../reference/index.html">Data</a>
</li>
<li>
  <a href="https://github.com/CrumpLab/TalkTyping">
    <span class="fa fa-lg fa-github"></span>
     
    source code
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Typing and Talking: draft in progress</h1>
                        <h4 class="author">Matthew J. C. Crump</h4>
            <address class="author_afil">
      1,2<br><a class="author_email" href="mailto:#"></a><a href="mailto:mcrump@brooklyn.cuny.edu" class="email">mcrump@brooklyn.cuny.edu</a>
      </address>
                              <h4 class="author">Nicholaus Brosowsky</h4>
            <address class="author_afil">
      2<br><h4 class="author">Lawrence Behmer</h4>
            <address class="author_afil">
      1<br><div class="hidden name"><code>Talk_typing_draft.Rmd</code></div>

    </address>
</address>
</div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      Enter abstract here. Each new line herein must be indented, like this line.
    </div>
    
<p>People have the ability to construct ideas and optionally turn them into actions. For example, people can think about an idea, and then decide whether to say the idea out loud in the form of a sentence. The control procesess responsible for translating ideas into action in language production are not fully understood. In particular, we suggest that multi-threading abilities are one aspect of the translation process that is not well understood. We borrow the term mult-threading from computing, where it refers to the ability of a central processing unit to make use of a common code at one level, to control the output of different threads at other levels. An example of multi-threading in language production is the ability to produce language in different formats, such as speaking out loud, or writing or typing. We investigate the general idea that common word-level linguistic codes used for speech act as inputs to control manual keystroke during typing.</p>
<!--

How language production converts ideas into actions remains unresolved. In part

Language production processes turn ideas into actions. 


We investigate whether verbal language production for speech is recruited to facilitate manual control of fingers for sequencing keystrokes during typewriting. In particular, we investigate the general idea that the sequence production processes enabling fluent typing are controlled by common word-level linguistic codes used during speech. We review three perspectives from the typing, language production, and sequence production literatures that all suggest an important role for verbal codes to mediate keystroke production in typing. 

-->
<!--
Intro paragraph what this is about

Typing theory: word-representations 
 - two loop theory, word is interface
 - old and new computational theories:
    - word activates all letters in parallel
    - word context drives serial ordering

Typing evidence: word-representations
  - words are typed faster than random strings
  - first letter slowing (word loading)
  - mid-word slowing (syllable loading)
  - 

Open Questions:


-->
<div id="hierarchical-control-and-typing" class="section level2">
<h2 class="hasAnchor">
<a href="#hierarchical-control-and-typing" class="anchor"></a>Hierarchical control and typing</h2>
<p>Typing is assumed to be controlled by hierarchically nested control loops <span class="citation">(Logan and Crump 2011)</span>. The outer loop relies on language comprehension and production to turn ideas into words and sentences. Word level-representations are then sent as goals to an inner loop that controls individual finger movements to individual keystrokes for each letter in a word.</p>
<p>The two loops are informationally encapsulated modules <span class="citation">(Fodor 1983)</span>, and the outer loop does not know the details of how the inner loop accomplishes keystrokes <span class="citation">(Logan and Crump 2009; Liu, Crump, and Logan 2010)</span>. However, the two loops must nevertheless be coordinated to accomplish accurate typing. Coordination is theorized to be accomplished by intermediate word-level representations. In other words, the tacit assumption is that multi-threading enables word production for typing to be controlled by the same word-level codes used for speaking.</p>
<p>These ideas have been instantiated by formal computational models of typing in different ways. For example, in <span class="citation">Rumelhart and Norman (1982)</span> typing model, word representations cause the parallel activation of letter units in a response scheduling buffer, which then controls individual keystrokes for all letters in the word. More recently, <span class="citation">Logan (2018)</span> showed that general memory process could use word-level representations to control the sequential execution of letter-level actions by a context, retrieval, and updating process (CRU). Although both models explain the process of serial ordering by different mechanisms, they commonly rely on higher level word-level codes to trigger lower level actions at the keystroke level.</p>
</div>
<div id="evidence-for-word-level-representations-in-typing" class="section level2">
<h2 class="hasAnchor">
<a href="#evidence-for-word-level-representations-in-typing" class="anchor"></a>Evidence for word-level representations in typing</h2>
<p>Several line of evidence are consistent with word-level representations from the outer loop providing control functions over inner loop keystroke sequencing processes. We describe the evidence, and then consider whether the word-level representations controlling typing are the same one used for controlling speech, which would suggest that language production can output actions in a multi-threaded fashion, with threads for speech and typing.</p>
<p>Typing speed is fastest for words and decreases as letter strings approach random orders <span class="citation">(Shaffer and Hardwick 1968; Behmer and Crump 2017)</span>. This finding is consistent with the idea that typists use word-representations to control fluent typing, and that typing becomes disfluent when word-representations (e.g., for random strings) are unavailable. At the same time, the differences between typing words and non-word strings that approximate the structure of words to various degrees could reflect a frequency sensitive learning process <span class="citation">(Logan 1988)</span> that operates at the letter level, or n-gram level (e.g., letter bigrams or trigrams).</p>
<p>First-letter and mid-word slowing phenomenon <span class="citation">(Ostry 1983)</span> in typing show that the first letter in a word is typed more slowly than the remaining letters, and the middle letter in a word is generally typed more slowly than the surrounding letters. First letter slowing could reflect the planning or buffering time necessary for the outer loop to construct and send a word-level represention to the inner loop. Mid-word slowing could reflect a similar planning process operating at the level of syllables <span class="citation">(Massaro and Lucas 1984; Pinet, Ziegler, and Alario 2016; Will, Nottbusch, and Weingarten 2006)</span>, which appear in the middle of words. Alternatively, <span class="citation">Crump, Lai, and Brosowsky (n.d.)</span> proposed that first and middle letter slowing could be explained by letter-level informational uncertainty, as a function of letter position, word length, and previous letter contexts. Although the found that letter uncertainty explained a large portion of the variance in keystroke times for letters in the contexts, they also found that first letter keystroke times were longer than would be expected on the basis of letter uncertainty alone. They concluded that first-letter slowing reflects a combination of planning time and learned sensitivity to the predictability of letters in those contexts.</p>
<p>Last, <span class="citation">Crump and Logan (2010)</span> showed that words and nonwords differentially prime their constituent letters. They presented a word or non-word as a prime, and then had subjects respond to a subsequent letter probe. Word string primes facilitated letters for all positions in a word, compared to letters not in the word. However, non-word string primes only showed facilitation for letter probes from the first position in the string. This finding suggests that a word-level representation plays a role in facilitating the production of all of its constituent letters.</p>
</div>
<div id="common-codes-and-multi-threaded-language-production" class="section level2">
<h2 class="hasAnchor">
<a href="#common-codes-and-multi-threaded-language-production" class="anchor"></a>Common codes and multi-threaded language production</h2>
<p>The output of language production can take several forms, including speaking (out loud, or silenty using inner voice), writing, typing, and signing. Each output modality requires specific motor control operations for successful action production.Additionally, people appear capable of producing language in multiple modes at the same time. For example, I am saying these words using my inner voice while my fingers type the letters. The control structures translating higher-level ideas into lower-level, modality specific motor output streams are not well-understood; especially, when multiple output streams are available potentially working simultaneously.</p>
<div id="one-outer-loop-to-many-inner-loops" class="section level3">
<h3 class="hasAnchor">
<a href="#one-outer-loop-to-many-inner-loops" class="anchor"></a>One outer loop to many inner loops</h3>
<p>We consider some ways in which the hierchical control assumptions from the two-loop theory of typing might be generalized to account for multiple, simultaneous modes of language production. First, a single outer loop might provide common word-level representations sent to multiple inner loops to control action within each output mode. We would also assume that inner loops for talking, writing, typing, or signing, would depend on practice, and would only be highly automatized for highly practiced modes of communication. In this way, an inner loop for speech production and typing production might capable of running in parallel, while being served the same word-level instructions from the outer loop. This one-to-many account raises further questions about the serial versus parallel nature of the inner loops. For example, if the an inner loop for speech is fully autonomous from an inner loop for typing, then they might be expected to run simultaneously without one process interfering with another. At the same, if both loops are being triggered by shared word-level codes, then manipulations that influence how the outer loop produces word representations for word production should have a cascading and common influence on speech and typing production. For example, having typists speak one word while typing another word might be expected to disrupt typing ability, because interference between word-level representations in the outer-loop created by the demand to speak one word, could interfere with the demand to type a different word.</p>
</div>
<div id="many-outer-loops-to-many-inner-loops" class="section level3">
<h3 class="hasAnchor">
<a href="#many-outer-loops-to-many-inner-loops" class="anchor"></a>Many outer loops to many inner loops</h3>
<p>The nature of the outer loop in the two loop theory of typing is not well understood or explained. This loop is granted the extraordinary ability to generate ideas and translate them into sentences and words. It is unclear whether the outer loop should be thought of as a singular or multi-loop process. For example, if the outer loop could generate multiple ideas at the same time, each idea might be thought of as an independent loop capable of interfacing with a particular inner loop for output. In this case, a person might be able to use one outer loop to construct a word to control speech prodution, and another outer loop to construct a different word to control typing production. This many-to-many loop framework raises similar questions about the capacity for independent and simulatenous loop operation.</p>
<p>to what extent do people have the ability to control language production in a multi-threaded fashion, allowing multiple inner loop modes of language production to proceeed from commands given by a single higher-order outer loop?</p>
<p>There are several open questions about the potential constraints on multi-threaded language production. One possibility is that each inne</p>
<!--



-->
<p>This effect of string structure could simply reflect familiarity and prior experience with typing words compared to random letter sequences, but could also be driven by string pronounceability. For example, typing speed is also influenced by syllabic structure, with faster interkeystroke times for letters within versus between syllables in a word. Word-level representations may also have a special status in activating all constituent letters in parallel compared to non-words which do not activate all letters in a sequence (). Finally, lexical structure at the level of bigrams appears to influence the spatial precision with which typists locate keys during typing (). This evidence is consistent with the idea that typists use verbal codes in a straightforward manner during typing, by concurrently using their inner voice (and perhaps sometimes speaking out loud) to say the same words they are typing.</p>
<p>Other work looking at dual-task interference in typing suggests that fast and accurate typing may not necessarily depend on using verbal codes. Protection from dual-task interference is often interpreted as evidence that is a skill is highly automatized, and typing in general appears to be highly automatized. For example, typing speed in a dual task-condition to identify auditory tones with a foot-pedal was only 4ms slower than normal typing. Remarkably, Shaffer (1975) showed that typing speed was mostly unaffected under concurrent task demands to recite an unrelated nursery rhyme while typing. However, typing speed was slowed substantially when typists copied spoken words while simultaneously reading unrelated visually presented text. And, these data were collected only from a single skilled typist, and whether the result is generalizable remains unclear. On the one hand, if the same verbal codes used for speech are used for typing, it is surprising that a typist could easily type one set of words while saying another set of words out loud without interference. On the other hand, interference appears to depend on the details of how verbal codes are used, as interference was observed when typists attempted to read unrelated text while copying spoken words.</p>
<p>The purpose of the present work is to clarify whether and how typists use verbal codes during typing. One possibility is that verbal codes for speech do not participate directly in the control of keystrokes for typing. On this view, typing could be considered a highly automatized and modularized skill that runs largely independently from other language production processes. Although speaking and typing may often go hand in hand, as many typists report silently voicing the words they are typing while they produce text (see Experiment 1), overt or covert speech production during typing could be carried out independently and in parallel with the motor movements required for typing. Another general possibility is that typists co-opt existing speech production processes during typing, so that normal typing is deeply connected at some level to a common language production process. We test these two general ideas in a series of related typing tasks that manipulate what typists say while they are typing. A central empirical aim was to tax concurrent speech production processes with reciting relevant or irrelevant content during copy-typing. In this way, we could establish boundary conditions for observing interference (or the lack thereof) from speech production on keystroke production.</p>
<p>In Experiment 1a and 1b we had typists speak the words or letters they were typing either silently or out loud. This experiment tested the idea that typists use verbal codes at the word rather than letter level during typing. The remaining experiments investigated the extent to which typing performance can be impaired by disrupting normal speech production. Experiment 2 measured copy-typing performance across several verbal suppression conditions where typists were instructed to repeat words or letter (unrelated to the text they were copying) out loud as they typed. Experiment 3 measured copy-typing performance under conditions of delayed auditory feedback, which is known to disrupt fluent speech.</p>
</div>
</div>
<div id="experiment-1a-and-1b-speaking-words-or-letters-during-typing" class="section level1">
<h1 class="hasAnchor">
<a href="#experiment-1a-and-1b-speaking-words-or-letters-during-typing" class="anchor"></a>Experiment 1a and 1b: Speaking words or letters during typing</h1>
<p>The immediate goal of typing is to produce letters in the correct order during word and sentence production. Based on the idea that verbal codes are used during typing, we assumed that typists routinely verbalize, either covertly or overtly, aspects of the letters they are typing. For example, as I type this sentence, my subjective experience is that I silently voice the words I am typing. In Experiment 1a, we asked typists recruited online from Amazon’s mechanical turk to copy-type a paragraph under two conditions to silently voice each word as they typed, or silently voice each letter as they typed. To gain an understanding of the subjective experience of using the inner voice during typing, we also asked typists to report what their inner voice usually says during typing (e.g., words, letters, both, or none). Because we had no way of controlling whether our subjects adopted our instructions, we conducted Experiment 1b as a lab-based replication and extension of Experiment 1a. Here, subjects copied five paragraphs. The first paragraph involved only the instruction to copy-type as quickly and accurately as possible. Across the remaining four paragraphs we manipulated whether subjects spoke out loud or silently to themselves, combined factorially with whether they spoke words or letters during typing. If typists use verbal codes at the word level during typing, then we expected that typing speed should be faster when subjects were instructed to say words rather than letters as they typed.</p>
<div id="methods" class="section level2">
<h2 class="hasAnchor">
<a href="#methods" class="anchor"></a>Methods</h2>
<div id="subjects" class="section level3">
<h3 class="hasAnchor">
<a href="#subjects" class="anchor"></a>Subjects</h3>
<p>In experiment 1a, 50 subjects were recruited from AMT and compensated $0.25 for participating in the approximately 5 minute task. 40 subjects completed the task and were included in the analysis. In experiment 1b, 16 subjects were recruited from the undergraduate population at Brooklyn College, and received course credit for their participation. One subject was not included in the analysis because they repeatedly typed “asdf”, rather than completing the task.</p>
</div>
<div id="apparatus-stimuli" class="section level3">
<h3 class="hasAnchor">
<a href="#apparatus-stimuli" class="anchor"></a>Apparatus &amp; Stimuli</h3>
<p>For experiment 1a, typing tests were programmed for the online environment using HTML and JavaScript and conducted in subjects’ web-browsers. For experiment 1b, typing tests were conducted on an iMac (21" screen) controlled by LIVECODE software. Typing responses were registered on a standard QWERTY keyboard. Each paragraph in the typing task involved copy-typing short paragraphs (~115 words length), taken from Logan and Zbrodoff (1998).</p>
</div>
<div id="design-and-procedure" class="section level3">
<h3 class="hasAnchor">
<a href="#design-and-procedure" class="anchor"></a>Design and Procedure</h3>
<p>During the task, participants were shown each paragraph in a text box. Paragraph text was black and presented in 14pt, Helvetica font. In general, participants were instructed to begin typing with the first letter in the paragraph. Correctly typed letters turned green, and typists could only proceed to the next by typing the current letter correctly. For each of the different typing conditions, subjects were presented with the following instructions.</p>
<p>For experiment 1a, the instructions read: This experiment tests how you your inner voice influences your typing ability. When you type this paragraph, use your inner voice to say each word (or letter in the letter condition) that you type. At the beginning of the experiment, subjects were also asked to choose whether they use their inner voice during typing to speak either words or letters.</p>
<p>For experiment 1b, in the speak aloud condition, the instructions read: When you type this paragraph, speak aloud each word (or letter in the letter condition) that you type. In the inner voice condition, the instructions were identical to experiment 1a. At the beginning of the experiment, subjects were given a short questionnaire about how they use their inner voice during typing. The questionnaire stated “People have the ability to use their inner voice to speak silently to themselves. We are interested in how you use your inner voice while you are typing. Please estimate the percentage of times that your inner voice is engaged in each of the following tasks while typing, and make sure your numbers add up to 100.”. The four tasks were: a) inner voice is silent, b) inner voice speaks words that you are typing, c) inner voice speaks letters that you are typing, d) inner voice speaks other words or letters that you are not typing.</p>
</div>
</div>
<div id="results" class="section level2">
<h2 class="hasAnchor">
<a href="#results" class="anchor"></a>Results</h2>
<div id="experiment-1a" class="section level3">
<h3 class="hasAnchor">
<a href="#experiment-1a" class="anchor"></a>Experiment 1a</h3>
<p>For each subject, we applied the following pre-processing steps. We included IKSIs only for keystrokes involving a lower case letter, and only for correct keystrokes that were preceded by a correct keystroke. Outlier IKSIs were removed for each subject, on a cell-by-cell basis, using the <span class="citation">Van Selst and Jolicoeur (1994)</span> non-recursive moving criterion procedure, which eliminated approximately 0.05 of IKSIs from further analysis. An alpha criterion of .05 was set for all analyses.</p>
<p>Mean IKSIs for correctly typed letters were computed for each subject in each condition and submitted to a 2 (Linguistic Unit: Say Letters vs. Say Words) x 2 (Letter position: First letter vs. Middle Letter) repeated measures ANOVA. Mean IKSIs are displayed in Figure @ref(fig:E1Figure).</p>
<div class="figure">
<img src="Talk_typing_draft_files/figure-html/E1Figure-1.png" alt="Mean interkeystroke intervals (IKSIs in ms) and mean accuracy as a function of linguistic unit condition (Say Word vs. Say Letter), and letter position in word (first letter vs. middle letter). Middle letters were any remaining letter in the word." width="576"><p class="caption">
Mean interkeystroke intervals (IKSIs in ms) and mean accuracy as a function of linguistic unit condition (Say Word vs. Say Letter), and letter position in word (first letter vs. middle letter). Middle letters were any remaining letter in the word.
</p>
</div>
<p>The main effect of the linguistic unit condition was significant, <span class="math inline">\(F(1, 39) = 24.89\)</span>, <span class="math inline">\(\mathit{MSE} = 3,082.97\)</span>, <span class="math inline">\(p &lt; .001\)</span>, <span class="math inline">\(\hat{\eta}^2_G = .039\)</span>. Mean IKSIs were shorter when subjects were instructed to use their inner voice to say the words (170), rather than the letters (214) they were typing.</p>
<p>The main effect of letter position was significant, <span class="math inline">\(F(1, 39) = 22.28\)</span>, <span class="math inline">\(\mathit{MSE} = 6,784.80\)</span>, <span class="math inline">\(p &lt; .001\)</span>, <span class="math inline">\(\hat{\eta}^2_G = .074\)</span>. Mean IKSIs were longer for letters in the first position (223), compared to letters in the other positions (161).</p>
<p>The interaction between linguistic unit and letter position did not meet the significance criterion, <span class="math inline">\(F(1, 39) = 3.08\)</span>, <span class="math inline">\(\mathit{MSE} = 501.77\)</span>, <span class="math inline">\(p = .087\)</span>, <span class="math inline">\(\hat{\eta}^2_G = .001\)</span>.</p>
<p>A corresponding 2x2 repeated measures ANOVA was conducted on the mean accuracies for typing letters in each condition. Mean accuracies are shown in Figure @ref(fig:E1Figure). Accuracy was uniformly high in all conditions, and there were no main effects or interaction.</p>
<p>Last, prior to the experiments subjects were asked if their inner voice usually thinks in words or letters when they type. The proportions of subjects reporting thinking in words, letters, or who did not answer were 0.9, 0.08, 0.02, respectively.</p>
</div>
<div id="experiment-1b" class="section level3">
<h3 class="hasAnchor">
<a href="#experiment-1b" class="anchor"></a>Experiment 1b</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/load">load</a></span>(<span class="st">"E1B_workspace.RData"</span>)</a></code></pre></div>
<p>Similar pre-processing rules were applied to the data. The exception was that accuracy was calculated at the word level rather than the letter level because the lab version of the experiment did not record accuracy at the letter level. Instead, IKSIs from words that were typed correctly were included in the IKSI analysis. The same outlier elimination procedure was applied, which excluded an average of 0.06 observations from each condition The accuracy analysis was conducted at the word level. Mean IKSIs and word level accuracy for each condition are displayed in Figure @ref(fig:E1BFigure)</p>
<div class="figure">
<img src="Talk_typing_draft_files/figure-html/E1BFigure-1.png" alt="Mean interkeystroke intervals (IKSIs in ms) as a function of voice (silent vs. talking), linguistic unit (Say Letter vs. Say word), and letter position (first vs. middle); and, mean accuracy as a function of voice and linguistic unit." width="576"><p class="caption">
Mean interkeystroke intervals (IKSIs in ms) as a function of voice (silent vs. talking), linguistic unit (Say Letter vs. Say word), and letter position (first vs. middle); and, mean accuracy as a function of voice and linguistic unit.
</p>
</div>
<p>Mean IKSIs for correctly typed letters were computed for each subject in each condition and submitted to a 2 (Voice: Silent vs. Talk) x 2 (Linguistic Unit: words vs. letters) x 2 (Letter position: first vs. middle) repeated measures ANOVA.</p>
<p>The main effect of the linguistic unit condition was significant, <span class="math inline">\(F(1, 14) = 24.45\)</span>, <span class="math inline">\(\mathit{MSE} = 19,560.37\)</span>, <span class="math inline">\(p &lt; .001\)</span>, <span class="math inline">\(\hat{\eta}^2_G = .257\)</span>. Mean IKSIs were shorter when subjects were instructed to use their inner voice to say the words (217 ms), rather than the letters (343 ms) they were typing. The main effect of letter position was significant, <span class="math inline">\(F(1, 14) = 24.02\)</span>, <span class="math inline">\(\mathit{MSE} = 28,607.35\)</span>, <span class="math inline">\(p &lt; .001\)</span>, <span class="math inline">\(\hat{\eta}^2_G = .332\)</span>. Mean IKSIs were longer for the first letter (355 ms), compared to other letters (161 ms). The main effect of voice was not significant, . Mean IKSIs were shorter for silent speaking (269 ms), compared to talking out loud (290 ms). These main effects were qualified by two interactions.</p>
<p>The voice by letter position interaction was significant, <span class="math inline">\(F(1, 14) = 4.66\)</span>, <span class="math inline">\(\mathit{MSE} = 1,544.69\)</span>, <span class="math inline">\(p = .049\)</span>, <span class="math inline">\(\hat{\eta}^2_G = .005\)</span>. The first letter slowing effect was larger when subjects spoke out loud rather than with their inner voice. Similarly, the linguistic unit by letter position interaction was significant, <span class="math inline">\(F(1, 14) = 7.82\)</span>, <span class="math inline">\(\mathit{MSE} = 2,846.27\)</span>, <span class="math inline">\(p = .014\)</span>, <span class="math inline">\(\hat{\eta}^2_G = .016\)</span>. The first letter slowing effect was larger when subjects said the letters rather than the words as they typed. The three-way interaction was not significant, <span class="math inline">\(F(1, 14) = 3.28\)</span>, <span class="math inline">\(\mathit{MSE} = 1,410.80\)</span>, <span class="math inline">\(p = .091\)</span>, <span class="math inline">\(\hat{\eta}^2_G = .003\)</span>.</p>
<p>The analysis of accuracy at the word level showed only a main effect of linguistic unit, <span class="math inline">\(F(1, 14) = 17.96\)</span>, <span class="math inline">\(\mathit{MSE} = 0.00\)</span>, <span class="math inline">\(p = .001\)</span>, <span class="math inline">\(\hat{\eta}^2_G = .101\)</span>. Subjects typed words more accurately when they said letters (0.92) compared to words (0.87). The interaction between voice and linguistic unit was not significant, <span class="math inline">\(F(1, 14) = 1.46\)</span>, <span class="math inline">\(\mathit{MSE} = 0.00\)</span>, <span class="math inline">\(p = .247\)</span>, <span class="math inline">\(\hat{\eta}^2_G = .016\)</span>.</p>
<p>The mean responses for the inner voice questionnaire were that subjects’ inner voice was silent 3%, said words 69%, said letters 16%, or said unrelated words or letters 12% of the time during typing.</p>
</div>
</div>
<div id="discussion" class="section level2">
<h2 class="hasAnchor">
<a href="#discussion" class="anchor"></a>Discussion</h2>
<p>The main finding from both experiments was that mean typing speed was much faster when subjects covertly or overtly said the words they were typing rather than the letters they were typing. The behavioral data was also supported by the questionnaire data which showed that most subjects claim to use their inner voice to say the words they are typing rather than say letters, unrelated words or letters, or nothing at all. This finding is consistent with the idea that verbal codes at the word level are important mediators of keystroke production during typing.</p>
</div>
</div>
<div id="experiment-2-verbal-suppression" class="section level1">
<h1 class="hasAnchor">
<a href="#experiment-2-verbal-suppression" class="anchor"></a>Experiment 2: Verbal Suppression</h1>
<p>Verbal suppression techniques are commonly used in memory studies to prevent subjects from using their inner voice to verbally code and rehearse to-be-remembered information. The technique usually involves asking subjects to repeatedly recite a word or phrase out loud during the rehearsal period. As a result, verbal processes are occupied by the reciting the word, and presumed to be unavailable for rehearsing information in working memory. Experiment 2 asked whether similar verbal suppression techniques would also disrupt typing performance. We had subjects copy-type one of six paragraphs under one normal condition, and five verbal suppression conditions. Each verbal suppression condition had typists say words or letters out loud while they typed. These conditions included: a) repeating the word “the”, b) repeating the words Tuesday and Thursday, c) repeating the letters of the alphabet in order, d) repeating randomly chosen letters, and e) counting backwards from X.</p>
<div id="methods-1" class="section level2">
<h2 class="hasAnchor">
<a href="#methods-1" class="anchor"></a>Methods</h2>
<div id="subjects-1" class="section level3">
<h3 class="hasAnchor">
<a href="#subjects-1" class="anchor"></a>Subjects</h3>
<p>15 subjects were recruited from the undergraduate population at Brooklyn College, and received course credit for their participation.</p>
</div>
<div id="apparatus-stimuli-" class="section level3">
<h3 class="hasAnchor">
<a href="#apparatus-stimuli-" class="anchor"></a>Apparatus &amp; Stimuli.</h3>
<p>The same apparatus and stimuli from Experiment 1b were used in Experiment 2.</p>
</div>
<div id="design-and-procedure-" class="section level3">
<h3 class="hasAnchor">
<a href="#design-and-procedure-" class="anchor"></a>Design and Procedure.</h3>
<p>The same general typing test procedure from Experiment 1b was used, with the exception that typists copied six paragraphs. The instructions for each of the conditions were as follows:</p>
<pre><code>Normal Typing instructions:
Say the instructions:
Say Tuesday/Thursday instructions:
Say alphabet instructions:
Say random letters instructions:
Count instructions:</code></pre>
</div>
</div>
<div id="results-1" class="section level2">
<h2 class="hasAnchor">
<a href="#results-1" class="anchor"></a>Results</h2>
<p><img src="Talk_typing_draft_files/figure-html/suppression-1.png" width="700"></p>
<p>Mean IKSIs for correctly typed letters were computed for each subject in each condition and submitted to a one-way repeated measures ANOVA with Suppression condition (Normal, The, Tuesday/Thursday, Alphabet, Random, and Count) as the sole factor. Mean IKSIs in each condition are displayed in table 2.</p>
<p>The main effect of Suppression was significant, F () = , MSE = , p &lt; . Post-hoc tests showed that all mean IKSIs in all suppression conditions were significantly slower than the mean IKSI in the normal typing condition. Additionally, X was X etc.</p>
</div>
</div>
<div id="general-discussion" class="section level1">
<h1 class="hasAnchor">
<a href="#general-discussion" class="anchor"></a>General Discussion</h1>
<p>Language production processes turn ideas into actions. For example, people use utterances and gestures to convey semantic meaning during conversation; to preserve ideas in different mediums, such as hand-writing, typewriting, and dictation; and to plan and guide cognition and behavior in general. In Vygotszky’s () developmental tradition, children first acquire connections between actions and outcomes in the world around them with the words spoken to them by their caregivers, and then internalize the same language system as a tool to regulate their own cognition and behavior. In adulthood, people continue to talk out loud and silently to themselves using inner speech, and such self-directed language production is assumed to continue to regulate many aspects of cognition and behavior (). For example, in memory, the phonological loop transfers to-be-remembered information into long-term memory through short-term rehearsal <span class="citation">(Baddeley and Hitch 1974)</span>. The act of speaking out loud itself improves future retrieval, as shown by the production effect <span class="citation">(MacLeod et al. 2010)</span>; and, the process of naming may guide category learning by drawing attention toward diagnostic features (Lupyan,). Verbal recoding can facilitate learning and recall of lengthy sequences by casting elements into chunks with recallable names <span class="citation">(Miller 1956)</span>. In the completion of everyday tasks, <span class="citation">Botvinick and Plaut (2004)</span> argue that verbally coded instructions together with recurrent associative learning of real-world action sequences provide the control necessary for accomplishing routine tasks like making coffee or tea. Among these and other uses, a crowning achievement of language production is the ability to control the serial order of utterances to convey meaning in highly complex and flexible ways.</p>
<div id="verbal-codes-in-speech" class="section level2">
<h2 class="hasAnchor">
<a href="#verbal-codes-in-speech" class="anchor"></a>Verbal codes in speech</h2>
<p>People are capable of overt and covert speech, which may be mediated by a common language production process. For example, according to the flexible abstraction hypothesis (), the selection of individual phonemes during covert or overt speech is controlled by a common process with relatively abstract phonemic codes. These abstract codes retain deep semantic and lexical features, but lack many of the articulatory features necessary for speaking out loud. As a result, inner speech may rely on these more abstract codes, which explains evidence that errors in overt speech can be driven more by lexical than phonemic similarity (). At the same time, these abstract codes can be used flexibly and further modified by articulatory processes that fill in necessary additional features to achieve overt speech. Although the flexible abstraction hypothesis is concerned mainly with speech overt and covert speech production, it is worth considering whether it extends to nonverbal language production such as typing. For example, the same abstract verbal codes mediating inner speech may be co-opted and further specified by motor processes controlling finger movements to achieve accurate and fluid keystroke production.</p>
</div>
<div id="verbal-codes-in-sequence-production" class="section level2">
<h2 class="hasAnchor">
<a href="#verbal-codes-in-sequence-production" class="anchor"></a>Verbal codes in sequence production</h2>
<p>Sequence production more generally may also be mediated by verbal codes that trigger a plan-based mode of action control distinct from a more automatic stimulus-based mode of control (). For example, a stimulus-based mode of control refers to actions triggered in an automatic, reflex-like manner in response to well-learned cues from the environment. Whereas, a plan-based mode of control refers to goal-driven cognitive processes that set and supervise motor programs for complex sequencing of actions. Evidence for a distinction between control modes comes from the serial reaction time task <span class="citation">(SRT, Nissen and Bullemer 1987)</span>. The major finding from SRT tasks is that subjects learn to respond faster to targets that are presented in repeating or probabilistic sequences compared to random sequences, even if they are unable to explicitly describe the sequential regularities. At the same time, whether reaction times are sensitive to the frequency of particular targets or first-order transitions (e.g., repetitions or alternations) appears to depend on whether subjects possess explicit knowledge about sequential regularities in the task. For example, in a task where alternations were three times more likely than repetitions, subjects who were not aware of the manipulation showed faster responses to the more frequent alternations than repetitions, whereas subjects who were aware of the manipulation were equally fast for alternations and repetitions. One interpretation is that explicit knowledge of the transition probabilities allowed subjects to adopt a control-based mode, enabling action plans to mediate responses rather than more automatic frequency sensitive learning processes. Using a similar task, Tubau, Hommel, &amp; López-Moliner (2007) further showed that subjects were more likely to adopt a plan-based mode (as evidenced by the elimination of the alternation benefit) when visual/verbal targets were used and when responses where followed by sounds, and plan-based control was disrupted when auditory noise was introduced. They suggested that use of phonemic codes in general may strongly influence subjects to adopt a plan-based vs. stimulus-based mode of action control.</p>

</div>
</div>
<div id="references" class="section level1">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1"><span class="kw">r_refs</span>(<span class="dt">file =</span> <span class="st">"r-references.bib"</span>)</a></code></pre></div>

<div id="refs">
<div id="ref-BaddeleyWorkingmemory1974">
<p>Baddeley, Alan D., and G. J. Hitch. 1974. “Working Memory.” <em>The Psychology of Learning and Motivation</em> 8: 47–89.</p>
</div>
<div id="ref-behmer_crunching_2017">
<p>Behmer, Lawrence P., and M. J. C. Crump. 2017. “Crunching Big Data with Finger Tips: How Typists Tune Their Performance Towards the Statistics of Natural Language.” In <em>Big Data in Cognitive Science</em>, edited by Michael N. Jones, 319–41.</p>
</div>
<div id="ref-BotvinickDoingschemahierarchies2004">
<p>Botvinick, Matthew M., and David C. Plaut. 2004. “Doing Without Schema Hierarchies: A Recurrent Connectionist Approach to Normal and Impaired Routine Sequential Action.” <em>Psychological Review</em> 111 (2): 395–429.</p>
</div>
<div id="ref-crump2010hierarchical">
<p>Crump, Matthew JC, and Gordon D Logan. 2010. “Hierarchical Control and Skilled Typing: Evidence for Word-Level Control over the Execution of Individual Keystrokes.” <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em> 36 (6): 1369.</p>
</div>
<div id="ref-crump2018instance">
<p>Crump, Matthew, Walter Lai, and Nicholaus Brosowsky. n.d. “Instance Theory Predicts Information Theory: Episodic Uncertainty as a Determinant of Keystroke Dynamics.”</p>
</div>
<div id="ref-Fodormodularitymindessay1983">
<p>Fodor, Jerry A. 1983. <em>The Modularity of Mind: An Essay on Faculty Psychology</em>. Cambridge, Mass.: MIT Press.</p>
</div>
<div id="ref-Liuyouknowwhere2010">
<p>Liu, Xianyun, M. J. C. Crump, and Gordon D. Logan. 2010. “Do You Know Where Your Fingers Have Been? Explicit Knowledge of the Spatial Layout of the Keyboard in Skilled Typists.” <em>Memory &amp; Cognition</em> 38 (4): 474–84. <a href="https://doi.org/10.3758/MC.38.4.474">https://doi.org/10.3758/MC.38.4.474</a>.</p>
</div>
<div id="ref-logan_toward_1988">
<p>Logan, Gordon D. 1988. “Toward an Instance Theory of Automatization.” <em>Psychological Review</em> 95: 492–527. <a href="http://psycnet.apa.org/journals/rev/95/4/492/">http://psycnet.apa.org/journals/rev/95/4/492/</a>.</p>
</div>
<div id="ref-logan_2018">
<p>———. 2018. “Automatic Control: How Experts Act Without Thinking.” <em>Psychological Review</em> 125: 453–85.</p>
</div>
<div id="ref-Loganlefthanddoesn2009a">
<p>Logan, Gordon D., and M. J. C. Crump. 2009. “The Left Hand Doesn’t Know What the Right Hand Is Doing: The Disruptive Effects of Attention to the Hands in Skilled Typewriting.” <em>Psychological Science</em> 20 (10): 1296–1300.</p>
</div>
<div id="ref-LoganHierarchicalcontrolcognitive2011">
<p>———. 2011. “Hierarchical Control of Cognitive Processes: The Case for Skilled Typewriting.” In <em>Psychology of Learning and Motivation</em>, edited by B. H. Ross, 54:1–27. Elsevier.</p>
</div>
<div id="ref-MacLeodproductioneffectDelineation2010">
<p>MacLeod, Colin M., Nigel Gopie, Kathleen L. Hourihan, Karen R. Neary, and Jason D. Ozubko. 2010. “The Production Effect: Delineation of a Phenomenon.” <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em> 36 (3): 671–85.</p>
</div>
<div id="ref-massaro_typing_1984">
<p>Massaro, Dominic W., and Peter A. Lucas. 1984. “Typing Letter Strings Varying in Orthographic Structure.” <em>Acta Psychologica</em> 57: 109–31.</p>
</div>
<div id="ref-Millermagicalnumberseven1956">
<p>Miller, George A. 1956. “The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information.” <em>Psychological Review</em> 63 (2): 81–97.</p>
</div>
<div id="ref-NissenAttentionalrequirementslearning1987">
<p>Nissen, Mary Jo, and Peter Bullemer. 1987. “Attentional Requirements of Learning: Evidence from Performance Measures.” <em>Cognitive Psychology</em> 19 (1): 1–32.</p>
</div>
<div id="ref-ostry_determinants_1983">
<p>Ostry, David J. 1983. “Determinants of Interkey Times in Typing.” In <em>Cognitive Aspects of Skilled Typewriting</em>, edited by W. E. Cooper, 225–46. Springer-Verlag, New York.</p>
</div>
<div id="ref-PinetTypingwritingLinguistic2016">
<p>Pinet, Svetlana, Johannes C. Ziegler, and F.-Xavier Alario. 2016. “Typing Is Writing: Linguistic Properties Modulate Typing Execution.” <em>Psychonomic Bulletin &amp; Review</em> 23 (6): 1898–1906.</p>
</div>
<div id="ref-RumelhartSimulatingskilledtypist1982">
<p>Rumelhart, David E., and Donald A. Norman. 1982. “Simulating a Skilled Typist: A Study of Skilled Cognitive-Motor Performance.” <em>Cognitive Science</em> 6 (1): 1–36.</p>
</div>
<div id="ref-shaffer_typing_1968">
<p>Shaffer, L. H., and J. Hardwick. 1968. “Typing Performance as a Function of Text.” <em>The Quarterly Journal of Experimental Psychology</em> 20: 360–69.</p>
</div>
<div id="ref-van1994solution">
<p>Van Selst, Mark, and Pierre Jolicoeur. 1994. “A Solution to the Effect of Sample Size on Outlier Elimination.” <em>The Quarterly Journal of Experimental Psychology Section A</em> 47 (3): 631–50.</p>
</div>
<div id="ref-will_linguistic_2006">
<p>Will, Udo, Guido Nottbusch, and Rüdiger Weingarten. 2006. “Linguistic Units in Word Typing: Effects of Word Presentation Modes and Typing Delay.” <em>Written Language &amp; Literacy</em> 9: 153–76.</p>
</div>
</div>

</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#hierarchical-control-and-typing">Hierarchical control and typing</a></li>
      <li><a href="#evidence-for-word-level-representations-in-typing">Evidence for word-level representations in typing</a></li>
      <li><a href="#common-codes-and-multi-threaded-language-production">Common codes and multi-threaded language production</a></li>
      <li>
<a href="#experiment-1a-and-1b-speaking-words-or-letters-during-typing">Experiment 1a and 1b: Speaking words or letters during typing</a><ul class="nav nav-pills nav-stacked">
<li><a href="#methods">Methods</a></li>
      <li><a href="#results">Results</a></li>
      <li><a href="#discussion">Discussion</a></li>
      </ul>
</li>
      <li>
<a href="#experiment-2-verbal-suppression">Experiment 2: Verbal Suppression</a><ul class="nav nav-pills nav-stacked">
<li><a href="#methods-1">Methods</a></li>
      <li><a href="#results-1">Results</a></li>
      </ul>
</li>
      <li>
<a href="#general-discussion">General Discussion</a><ul class="nav nav-pills nav-stacked">
<li><a href="#verbal-codes-in-speech">Verbal codes in speech</a></li>
      <li><a href="#verbal-codes-in-sequence-production">Verbal codes in sequence production</a></li>
      </ul>
</li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by <a href="https://crumplab.github.io">Matthew Crump</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
